{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Shakespeare-allPlays.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_tyDh4_uxgA",
        "colab_type": "text"
      },
      "source": [
        "The project is done on google colab. <br>\n",
        "\n",
        "# **Importing Libraries**<br>\n",
        "Importing all the required libraries\n",
        "\n",
        "**TfidfVectorizer** - Used to make a bag of words for the sentences, this method comprises of CountVector() which counts the the number of times a word is used and Tfidftransformer() which transforms the counts to a frequency and an inverse document frequency which gives us a better representation of the data as it weighs down the redundant words.<br>\n",
        "**LabelEncoder** - Onehotencoding the labels, finding unique classes and converting to number representation between 0 to (n-1) unique classes.<br>\n",
        "**Metrics** - accuracy_score and confusion_matrix for evaluation on the test dataset.<br><br>\n",
        "\n",
        "**Other libraries used but not considered:**<br>\n",
        "from sklearn.feature_extraction.text import TfidfTransformer<br>\n",
        "from sklearn.feature_extraction.text import CountVectorizer<br>\n",
        "These ended up using a lot of RAM and so a different approach using TfidfVectorizer() which combines these and runs more efficiently."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYiCcuk0lSsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import io"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLSO5WLBzsMz",
        "colab_type": "text"
      },
      "source": [
        "# Reading Data\n",
        "Using google colab which requires the file to be uploaded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weeziOR-lvKT",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "72d53465-3522-4ee4-e36f-1a6011841dc9"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-046a9ad0-4fbe-4ace-a690-9c62a438cb62\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-046a9ad0-4fbe-4ace-a690-9c62a438cb62\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Shakespeare_data.csv to Shakespeare_data (3).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11omeO3czzFQ",
        "colab_type": "text"
      },
      "source": [
        "Reading the uploaded data file into a pandas dataframe and printing out the head to see the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7ObXzRvlZ3N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "1caf1788-13bb-4db3-c7a4-e746ad12be94"
      },
      "source": [
        "path = io.BytesIO(uploaded['Shakespeare_data.csv'])\n",
        "df = pd.read_csv(path)\n",
        "df.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataline</th>\n",
              "      <th>Play</th>\n",
              "      <th>PlayerLinenumber</th>\n",
              "      <th>ActSceneLine</th>\n",
              "      <th>Player</th>\n",
              "      <th>PlayerLine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ACT I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SCENE I. London. The palace.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Enter KING HENRY, LORD JOHN OF LANCASTER, the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1.1</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "      <td>So shaken as we are, so wan with care,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1.2</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "      <td>Find we a time for frighted peace to pant,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1.3</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "      <td>And breathe short-winded accents of new broils</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1.4</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "      <td>To be commenced in strands afar remote.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1.5</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "      <td>No more the thirsty entrance of this soil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1.6</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "      <td>Shall daub her lips with her own children's bl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1.7</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "      <td>Nor more shall trenching war channel her fields,</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Dataline  ...                                         PlayerLine\n",
              "0         1  ...                                              ACT I\n",
              "1         2  ...                       SCENE I. London. The palace.\n",
              "2         3  ...  Enter KING HENRY, LORD JOHN OF LANCASTER, the ...\n",
              "3         4  ...             So shaken as we are, so wan with care,\n",
              "4         5  ...         Find we a time for frighted peace to pant,\n",
              "5         6  ...     And breathe short-winded accents of new broils\n",
              "6         7  ...            To be commenced in strands afar remote.\n",
              "7         8  ...          No more the thirsty entrance of this soil\n",
              "8         9  ...  Shall daub her lips with her own children's bl...\n",
              "9        10  ...   Nor more shall trenching war channel her fields,\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KliJK9Ynz7hJ",
        "colab_type": "text"
      },
      "source": [
        "# Cleaning the Dataset<br>\n",
        "Dropping rows with a NaN value as these could be noisy for the training/testing purposes.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOLHJW9JmDeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.dropna()\n",
        "df = df.reset_index(drop=True)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbnwZPYs0WkI",
        "colab_type": "text"
      },
      "source": [
        "#Data Preparation:<br>\n",
        "I considered PlayerLine and the Play as the input features for the ml model to predict the player.<br>\n",
        "\n",
        "These two columns are text also the target column is a string, we need to change their representation to a numeric one so that a machine learning algorithm can understand/mase sense of the data and target.<br>\n",
        "\n",
        "For the PlayerLine column as it has sentences I use the technique of Bag of Words. For this I used tfidfVectorizer() from scikit-learn feature extraction, which counts the frequency of a word in a document giving us a representation with which number is important and which is not. The method also multiplies this count with an inverse document frequency which weighs the number according to how important they are within a document. The end result is a bag of words with a number representation that a machine learning model can take as an input.<br>\n",
        "\n",
        "For the Play and the Player (target) columns I used the labelEncoder() from scikit-learn which gives all the unique classes a number between 1 to (n-1) unique classes and using this I transformed these columns to a number representation which can now be used as an input and target data points for a machine learning model.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2urfL8bjmGkq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "16cd5db6-e63c-46a7-d5eb-60b3b76fb6b6"
      },
      "source": [
        "df[[\"PlayerLine\",\"Play\",\"Player\"]].head(3)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PlayerLine</th>\n",
              "      <th>Play</th>\n",
              "      <th>Player</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So shaken as we are, so wan with care,</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Find we a time for frighted peace to pant,</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>And breathe short-winded accents of new broils</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       PlayerLine      Play         Player\n",
              "0          So shaken as we are, so wan with care,  Henry IV  KING HENRY IV\n",
              "1      Find we a time for frighted peace to pant,  Henry IV  KING HENRY IV\n",
              "2  And breathe short-winded accents of new broils  Henry IV  KING HENRY IV"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTKQd1l40mfD",
        "colab_type": "text"
      },
      "source": [
        "Shape of the input features and target label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_Adu-Q0ILdX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73dd409c-bbfe-47c8-9a7f-5e1027607fb6"
      },
      "source": [
        "print(df[[\"PlayerLine\",\"Play\"]].shape,df[\"Player\"].shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(105152, 2) (105152,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp-7Xvxl0urN",
        "colab_type": "text"
      },
      "source": [
        "# Transforming Data\n",
        "As the whole dataset is being used limiting the dimension space, using TfidfVectorizer() here with a min_df of 10 which reduces the dimension space as it ignores the words occurring less then 10 times in the document most of my time was spent on optimizing this parameter so that I can have the whole data prepared to be used. Used (1,2) for ngram_range as this specifies the vectorizer to use both unigrams and bigrams. Used 'english' (only option currently available) as stop_words as it reduces the dimension space by ignoring frequently ocurring common english words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i1TfkESmJ0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf = TfidfVectorizer(min_df=10, ngram_range=(1, 2), stop_words='english')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxEOnGFw9kR-",
        "colab_type": "text"
      },
      "source": [
        "**Shuffling the whole dataset so that the plays are not grouped together, also so the traning and testing dataset are fairly balanced**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gi1uOg52pEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df = df.loc[df['Play']=='Henry IV']\n",
        "df = df.sample(frac = 1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfVmf2oD98ZK",
        "colab_type": "text"
      },
      "source": [
        "Transforming the text in the PlayerLine column into a term frequency matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcYqKuHMLPyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_pl = tfidf.fit_transform(df['PlayerLine']).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z1oQKSf-H19",
        "colab_type": "text"
      },
      "source": [
        "Making the label encoders for Player and Play to convert the unique classes to a range of numbers between 0 to (n-1) unique classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGi5KKIBC1dB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "62f9db04-98ff-432a-e351-dfabc25ba967"
      },
      "source": [
        "playerLabel = LabelEncoder()\n",
        "playLabel = LabelEncoder()\n",
        "X_pl.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105152, 5563)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVd3uJNW-TCA",
        "colab_type": "text"
      },
      "source": [
        "Transforming the Player and Play column into numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dlk50zjfDHPn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb35b6db-0648-4e25-9825-4c620d29473e"
      },
      "source": [
        "y_t = playerLabel.fit_transform(df['Player'])\n",
        "X_p = playLabel.fit_transform(df['Play']).reshape(-1,1)\n",
        "print(y_t.shape,X_p.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(105152,) (105152, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ou9n1zt-YXD",
        "colab_type": "text"
      },
      "source": [
        "Concatenating the traning dataset, using PlayerLine and Play as using the other features is increasing the memory requirements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uw6mEWJF-CB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c84b835d-416f-452a-b3fe-4411ff07c5eb"
      },
      "source": [
        "X_f = np.concatenate([X_pl,X_p],axis=1)\n",
        "X_f.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105152, 5564)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_aL7r1Q-hZX",
        "colab_type": "text"
      },
      "source": [
        "#Train Test split\n",
        "Splitting into train and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsZalJNJDf2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_f[:75000]\n",
        "y_train = y_t[:75000]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ0JhbCEFCkY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab5bd054-21c0-41b0-98e2-4e323a340c8c"
      },
      "source": [
        "X_pl = []\n",
        "X_p = []\n",
        "X_test = X_f[75000:]\n",
        "y_test = y_t[75000:]\n",
        "print(X_test.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30152, 5564) (30152,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f5XS1rJ-lYI",
        "colab_type": "text"
      },
      "source": [
        "# Implementing ML Models\n",
        "\n",
        "**As the logistic regression had the highest accuracy, only using that here** \n",
        "\n",
        "Data preparation complete, now we start testing ML models.<br><br>\n",
        "**MODELS USED**<br>\n",
        "Logistic Regression <br>\n",
        "~~Multinomial Naive Bayes~~ <br>\n",
        "~~Gaussian Naive Bayes~~<br>\n",
        "~~Multi Level Perceptron Classifier~~ <br>\n",
        "~~Linear Discriminant Analysis~~"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg0M48qDBomt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qpy0wEnn6ttM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = LogisticRegression(random_state=0,multi_class=\"multinomial\",solver=\"newton-cg\").fit(X_train, y_train)\n",
        "predsLR = lr.predict(X_test)\n",
        "print(\"\\nAccuracy score:\" , accuracy_score(y_test, predsLR))\n",
        "playerLabel.inverse_transform(lr.predict([X_test[0]]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6LCbnVj_NOQ",
        "colab_type": "text"
      },
      "source": [
        "# **Observations**<br>\n",
        "We can observe that when the whole dataset is used the accuracy of the logistic regression model is ...<br> \n",
        "*Training and inference to be finished*\n",
        "\n",
        "Previous testing (Not present in this notebook) with same optimization but using a Multinomial Naive Bayes resulted in a accuracy of 1.3% which is significantly lower than the accuracy found using Multinomial Naive Bayes when the data set is limited to only 1 play which is 20.04%. Which indicates that the logistic regression model on the same input data would also result in a lower accuracy even though if it had an accuracy of 24.4% on the limited dataset and this is due to the information which is being lost when the whole dataset is used in the bag of words representation.\n",
        "\n",
        "**Future Work**<br>\n",
        "We know as the data dimensions increase the training time of a machine learning model increases, also the RAM requirements increase. Since I did not have enough memory I had to limit the bag of words representation of PlayerLine column, since I did this some information was lost and so the machine learning model was not able to correctly predict the target required and hence the low accuracy. I think we can optimize the transformation which reduces the memory usage/requirements which can train a better ml model."
      ]
    }
  ]
}