{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Shakespeare-1Play(Henry-IV).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_tyDh4_uxgA",
        "colab_type": "text"
      },
      "source": [
        "The project is done on google colab. <br>\n",
        "\n",
        "# **Importing Libraries**<br>\n",
        "Importing all the required libraries\n",
        "\n",
        "**TfidfVectorizer** - Used to make a bag of words for the sentences, this method comprises of CountVector() which counts the the number of times a word is used and Tfidftransformer() which transforms the counts to a frequency and an inverse document frequency which gives us a better representation of the data as it weighs down the redundant words.<br>\n",
        "**LabelEncoder** - Onehotencoding the labels, finding unique classes and converting to number representation between 0 to (n-1) unique classes.<br>\n",
        "**Metrics** - accuracy_score and confusion_matrix for evaluation on the test dataset.<br><br>\n",
        "\n",
        "**Other libraries used but not considered:**<br>\n",
        "from sklearn.feature_extraction.text import TfidfTransformer<br>\n",
        "from sklearn.feature_extraction.text import CountVectorizer<br>\n",
        "These ended up using a lot of RAM and so a different approach using TfidfVectorizer() which combines these and runs more efficiently is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYiCcuk0lSsA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import io"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLSO5WLBzsMz",
        "colab_type": "text"
      },
      "source": [
        "# Reading Data\n",
        "Using google colab which requires the file to be uploaded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weeziOR-lvKT",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "2d1e90be-b32c-4d16-d1cb-cdf4ab5ab006"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-11c05425-1a24-41cb-8386-ba5649725e8e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-11c05425-1a24-41cb-8386-ba5649725e8e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Shakespeare_data.csv to Shakespeare_data (34).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11omeO3czzFQ",
        "colab_type": "text"
      },
      "source": [
        "Reading the uploaded data file into a pandas dataframe and printing out the head to see the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7ObXzRvlZ3N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "b224bc84-9d3b-489d-a5c9-b066eeb7e93f"
      },
      "source": [
        "path = io.BytesIO(uploaded['Shakespeare_data.csv'])\n",
        "df = pd.read_csv(path)\n",
        "df.head(10)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dataline</th>\n",
              "      <th>Play</th>\n",
              "      <th>PlayerLinenumber</th>\n",
              "      <th>ActSceneLine</th>\n",
              "      <th>Player</th>\n",
              "      <th>PlayerLine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ACT I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>SCENE I. London. The palace.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Enter KING HENRY, LORD JOHN OF LANCASTER, the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1.1</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "      <td>So shaken as we are, so wan with care,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1.2</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "      <td>Find we a time for frighted peace to pant,</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1.3</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "      <td>And breathe short-winded accents of new broils</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1.4</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "      <td>To be commenced in strands afar remote.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1.5</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "      <td>No more the thirsty entrance of this soil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1.6</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "      <td>Shall daub her lips with her own children's bl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.1.7</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "      <td>Nor more shall trenching war channel her fields,</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Dataline  ...                                         PlayerLine\n",
              "0         1  ...                                              ACT I\n",
              "1         2  ...                       SCENE I. London. The palace.\n",
              "2         3  ...  Enter KING HENRY, LORD JOHN OF LANCASTER, the ...\n",
              "3         4  ...             So shaken as we are, so wan with care,\n",
              "4         5  ...         Find we a time for frighted peace to pant,\n",
              "5         6  ...     And breathe short-winded accents of new broils\n",
              "6         7  ...            To be commenced in strands afar remote.\n",
              "7         8  ...          No more the thirsty entrance of this soil\n",
              "8         9  ...  Shall daub her lips with her own children's bl...\n",
              "9        10  ...   Nor more shall trenching war channel her fields,\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KliJK9Ynz7hJ",
        "colab_type": "text"
      },
      "source": [
        "# Cleaning the Dataset<br>\n",
        "Dropping rows with a NaN value as these could be noisy for the training/testing purposes.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOLHJW9JmDeL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.dropna()\n",
        "df = df.reset_index()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbnwZPYs0WkI",
        "colab_type": "text"
      },
      "source": [
        "#Data Preparation:<br>\n",
        "I considered PlayerLine and the Play as the input features for the ml model to predict the player."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2urfL8bjmGkq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "outputId": "b3e22314-a054-4753-f4a9-4f1db41b2d05"
      },
      "source": [
        "df[[\"PlayerLine\",\"Play\",\"Player\"]].head(3)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PlayerLine</th>\n",
              "      <th>Play</th>\n",
              "      <th>Player</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>So shaken as we are, so wan with care,</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Find we a time for frighted peace to pant,</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>And breathe short-winded accents of new broils</td>\n",
              "      <td>Henry IV</td>\n",
              "      <td>KING HENRY IV</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       PlayerLine      Play         Player\n",
              "0          So shaken as we are, so wan with care,  Henry IV  KING HENRY IV\n",
              "1      Find we a time for frighted peace to pant,  Henry IV  KING HENRY IV\n",
              "2  And breathe short-winded accents of new broils  Henry IV  KING HENRY IV"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTKQd1l40mfD",
        "colab_type": "text"
      },
      "source": [
        "Shape of the input features and target label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_Adu-Q0ILdX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e3229d46-f8bd-477b-a695-854796bf1468"
      },
      "source": [
        "print(df[[\"PlayerLine\",\"Play\"]].shape,df[\"Player\"].shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(105152, 2) (105152,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hp-7Xvxl0urN",
        "colab_type": "text"
      },
      "source": [
        "# Transforming Data\n",
        "Using TfidfVectorizer() here with a min_df of 10 which reduces the dimension space as it ignores the words occurring less then 10 times in the document. Used (1,2) for ngram_range as this specifies the vectorizer to use both unigrams and bigrams. Used 'english' (only option currently available) as stop_words as it reduces the dimension space by ignoring frequently ocurring common english words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8i1TfkESmJ0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfidf = TfidfVectorizer(min_df=1, ngram_range=(1, 2), stop_words='english')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxEOnGFw9kR-",
        "colab_type": "text"
      },
      "source": [
        "Limiting the dataset to just a single play. In this notebook play \"Henry IV\" is used."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gi1uOg52pEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df.loc[df['Play']=='Henry IV']"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfVmf2oD98ZK",
        "colab_type": "text"
      },
      "source": [
        "Transforming the text in the PlayerLine column into a term frequency matrix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcYqKuHMLPyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_pl = tfidf.fit_transform(df['PlayerLine']).toarray()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z1oQKSf-H19",
        "colab_type": "text"
      },
      "source": [
        "Making the label encoders for Player and Play to convert the unique classes to a range of numbers between 0 to (n-1) unique classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGi5KKIBC1dB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38aee66f-9f5c-448c-cc5b-4ac45597cb2d"
      },
      "source": [
        "playerLabel = LabelEncoder()\n",
        "playLabel = LabelEncoder()\n",
        "X_pl.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3044, 10656)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVd3uJNW-TCA",
        "colab_type": "text"
      },
      "source": [
        "Transforming the Player and Play column into numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dlk50zjfDHPn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a65ff7f8-0436-4cb1-b1a4-4b215d53662f"
      },
      "source": [
        "y_t = playerLabel.fit_transform(df['Player'])\n",
        "X_p = playLabel.fit_transform(df['Play']).reshape(-1,1)\n",
        "print(y_t.shape,X_p.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3044,) (3044, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ou9n1zt-YXD",
        "colab_type": "text"
      },
      "source": [
        "Concatenating the traning dataset, using PlayerLine and Play as using the other features is increasing the memory requirements."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uw6mEWJF-CB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "76dc78ef-51f0-4b66-dc47-29cce3f416e3"
      },
      "source": [
        "X_f = np.concatenate([X_pl,X_p],axis=1)\n",
        "X_f.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3044, 10657)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_aL7r1Q-hZX",
        "colab_type": "text"
      },
      "source": [
        "#Train Test split\n",
        "Splitting into train and test datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsZalJNJDf2C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_f[:2000]\n",
        "y_train = y_t[:2000]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQ0JhbCEFCkY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2a61aa24-e01d-422d-c933-564b374db6ed"
      },
      "source": [
        "X_pl = []\n",
        "X_p = []\n",
        "X_test = X_f[2000:]\n",
        "y_test = y_t[2000:]\n",
        "print(X_test.shape,y_test.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1044, 10657) (1044,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f5XS1rJ-lYI",
        "colab_type": "text"
      },
      "source": [
        "# Implementing ML Models\n",
        "Data preparation complete, now we start testing different ML models.<br><br>\n",
        "**MODELS USED**<br>\n",
        "Multinomial Naive Bayes <br>\n",
        "Gaussian Naive Bayes <br>\n",
        "Multi Level Perceptron Classifier <br>\n",
        "Linear Discriminant Analysis <br>\n",
        "Logistic Regression <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qg0M48qDBomt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e45E3qvtbAke",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "835a00f3-8b51-4a5c-a20a-5177366f759c"
      },
      "source": [
        "mnb = MultinomialNB().fit(X_train, y_train)\n",
        "predsMNB =  mnb.predict(X_test)\n",
        "print(\"\\nAccuracy score:\" , accuracy_score(y_test, predsMNB))\n",
        "playerLabel.inverse_transform(mnb.predict([X_test[0]]))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy score: 0.22126436781609196\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['KING HENRY IV'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQiMzw703a2C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "1f9f334e-0126-4500-ffb5-f557fabc4b21"
      },
      "source": [
        "gnb = GaussianNB().fit(X_train, y_train)\n",
        "predsGNB = gnb.predict(X_test)\n",
        "print(\"\\nAccuracy score:\" , accuracy_score(y_test, predsGNB))\n",
        "playerLabel.inverse_transform(gnb.predict([X_test[0]]))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy score: 0.15517241379310345\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Vintner'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tr9vjJA14RDV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "4f37de1c-6f72-46fd-8f1e-ccbbf48544d9"
      },
      "source": [
        "mlp = MLPClassifier(random_state=1, max_iter=200).fit(X_train, y_train)\n",
        "predsMLP = mlp.predict(X_test)\n",
        "print(\"\\nAccuracy score:\" , accuracy_score(y_test, predsMLP))\n",
        "playerLabel.inverse_transform(mlp.predict([X_test[0]]))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy score: 0.20402298850574713\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['GADSHILL'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_K7G8Ewp4Yj3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3d9add89-89a5-4cb0-f108-aa3cfdee9155"
      },
      "source": [
        "lda = LinearDiscriminantAnalysis().fit(X_train,y_train)\n",
        "predsLDA = lda.predict(X_test)\n",
        "print(\"\\nAccuracy score:\" , accuracy_score(y_test, predsLDA))\n",
        "playerLabel.inverse_transform(lda.predict([X_test[0]]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy score: 0.044061302681992334\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Chamberlain'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qpy0wEnn6ttM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f63064e8-f192-4109-aa4b-4f6c20fca7c0"
      },
      "source": [
        "lr = LogisticRegression(random_state=0,multi_class=\"multinomial\",solver=\"newton-cg\").fit(X_train, y_train)\n",
        "predsLR = lr.predict(X_test)\n",
        "print(\"\\nAccuracy score:\" , accuracy_score(y_test, predsLR))\n",
        "playerLabel.inverse_transform(lr.predict([X_test[0]]))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy score: 0.24042145593869732\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['FALSTAFF'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6LCbnVj_NOQ",
        "colab_type": "text"
      },
      "source": [
        "**Observations**<br>\n",
        "As we can see on this limited dataset of only one play i.e. \"Henry IV\" LogisticRegression has the highest accuracy with a 24.04% chance of correctly predicting the Player using the PlayerLine as input feature and Multinomial Naive Bayes coming in seconds with a 22.13% chance of correctly predicting."
      ]
    }
  ]
}